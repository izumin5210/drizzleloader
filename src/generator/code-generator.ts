import type { AnalyzedColumn, AnalyzedTable } from "../analyzer/types.js";
import {
  toCamelCase,
  toCompositeLoaderName,
  toPascalCase,
} from "../utils/naming.js";
import {
  analyzeRuntimeUsage,
  generateRuntimeFile,
} from "./runtime-generator.js";

const FILE_HEADER = `// This file is auto-generated by drizzleloader. DO NOT EDIT.

`;

export interface InternalFileOptions {
  schemaImport: string;
  dialect: "pg";
}

interface UniqueLoaderOptions {
  useHelpers: boolean;
}

function generateUniqueLoader(
  table: AnalyzedTable,
  columnName: string,
  tsType: string,
  options: UniqueLoaderOptions = { useHelpers: false },
): string {
  const loaderName = `by${toPascalCase(columnName)}`;
  const keysVar = `${toCamelCase(columnName)}s`;
  const tableName = table.name;
  const columnCamel = toCamelCase(columnName);

  if (options.useHelpers) {
    return `const ${loaderName} = new DataLoader<${tsType}, InferSelectModel<typeof __schema.${tableName}>>(
  async (${keysVar}) => {
    const rows = await db.select().from(__schema.${tableName}).where(inArray(__schema.${tableName}.${columnCamel}, [...${keysVar}]));
    const map = buildLookupMap(rows, (row) => row.${columnCamel});
    return ${keysVar}.map((key) => lookupOrError(map, key, "${tableName}", "${columnName}"));
  }
);`;
  }

  return `const ${loaderName} = new DataLoader<${tsType}, InferSelectModel<typeof __schema.${tableName}>>(
  async (${keysVar}) => {
    const rows = await db.select().from(__schema.${tableName}).where(inArray(__schema.${tableName}.${columnCamel}, [...${keysVar}]));
    const map = new Map(rows.map((row) => [row.${columnCamel}, row]));
    return ${keysVar}.map((key) => map.get(key) ?? new DrizzleLoaderNotFound({ table: "${tableName}", columns: [{ ${columnName}: key }] }));
  }
);`;
}

function generateNonUniqueLoader(
  table: AnalyzedTable,
  columnName: string,
  tsType: string,
): string {
  const loaderName = `by${toPascalCase(columnName)}`;
  const keysVar = `${toCamelCase(columnName)}s`;
  const tableName = table.name;
  const columnCamel = toCamelCase(columnName);

  return `const ${loaderName} = new DataLoader<${tsType}, InferSelectModel<typeof __schema.${tableName}>[]>(
  async (${keysVar}) => {
    const rows = await db.select().from(__schema.${tableName}).where(inArray(__schema.${tableName}.${columnCamel}, [...${keysVar}]));
    const map = new Map<${tsType}, InferSelectModel<typeof __schema.${tableName}>[]>();
    for (const row of rows) {
      const existing = map.get(row.${columnCamel}) ?? [];
      existing.push(row);
      map.set(row.${columnCamel}, existing);
    }
    return ${keysVar}.map((key) => map.get(key) ?? []);
  }
);`;
}

function generateCompositeNonUniqueLoader(
  table: AnalyzedTable,
  columns: AnalyzedColumn[],
): string {
  const loaderName = toCompositeLoaderName(columns.map((c) => c.name));
  const tableName = table.name;

  // Build key type: { authorId: number; category: string }
  const keyTypeFields = columns
    .map((col) => `${toCamelCase(col.name)}: ${col.tsType}`)
    .join("; ");
  const keyType = `{ ${keyTypeFields} }`;

  // Build column names array for helpers
  const columnNames = columns
    .map((col) => `"${toCamelCase(col.name)}"`)
    .join(", ");

  // Build column accessors for query
  const columnAccessors = columns
    .map((c) => `__schema.${tableName}.${toCamelCase(c.name)}`)
    .join(", ");

  return `const ${loaderName} = new DataLoader<${keyType}, InferSelectModel<typeof __schema.${tableName}>[], string>(
  async (keys) => {
    const rows = await queryCompositeKey(db, __schema.${tableName}, [${columnAccessors}], [${columnNames}], keys as readonly Record<string, unknown>[]);
    const map = buildCompositeLookupMap(rows, [${columnNames}] as const);
    return keys.map((key) => map.get(serializeCompositeKey(key, [${columnNames}] as const)) ?? []);
  },
  { cacheKeyFn: (key) => serializeCompositeKey(key, [${columnNames}] as const) }
);`;
}

function generateCompositeUniqueLoader(
  table: AnalyzedTable,
  columns: AnalyzedColumn[],
): string {
  const loaderName = toCompositeLoaderName(columns.map((c) => c.name));
  const tableName = table.name;

  const keyTypeFields = columns
    .map((col) => `${toCamelCase(col.name)}: ${col.tsType}`)
    .join("; ");
  const keyType = `{ ${keyTypeFields} }`;

  const columnNames = columns
    .map((col) => `"${toCamelCase(col.name)}"`)
    .join(", ");

  const columnAccessors = columns
    .map((c) => `__schema.${tableName}.${toCamelCase(c.name)}`)
    .join(", ");

  const errorColumns = `{ ${columns
    .map((col) => `${col.name}: key.${toCamelCase(col.name)}`)
    .join(", ")} }`;

  return `const ${loaderName} = new DataLoader<${keyType}, InferSelectModel<typeof __schema.${tableName}>, string>(
  async (keys) => {
    const rows = await queryCompositeKey(db, __schema.${tableName}, [${columnAccessors}], [${columnNames}], keys as readonly Record<string, unknown>[]);
    const map = buildCompositeLookupMap(rows, [${columnNames}] as const);
    return keys.map((key) => {
      const found = map.get(serializeCompositeKey(key, [${columnNames}] as const))?.[0];
      return found ?? new DrizzleLoaderNotFound({ table: "${tableName}", columns: [${errorColumns}] });
    });
  },
  { cacheKeyFn: (key) => serializeCompositeKey(key, [${columnNames}] as const) }
);`;
}

function getLoaderNames(table: AnalyzedTable): string[] {
  const names: string[] = [];

  if (table.primaryKey) {
    if (table.primaryKey.columns.length === 1 && table.primaryKey.columns[0]) {
      names.push(`by${toPascalCase(table.primaryKey.columns[0].name)}`);
    } else if (table.primaryKey.columns.length > 1) {
      names.push(
        toCompositeLoaderName(table.primaryKey.columns.map((c) => c.name)),
      );
    }
  }

  for (const idx of table.indexes) {
    if (idx.columns.length === 1 && idx.columns[0]) {
      names.push(`by${toPascalCase(idx.columns[0].name)}`);
    } else if (idx.columns.length > 1) {
      names.push(toCompositeLoaderName(idx.columns.map((c) => c.name)));
    }
  }

  return names;
}

function indentLines(text: string, spaces: number): string {
  const indent = " ".repeat(spaces);
  return text
    .split("\n")
    .map((line) => indent + line)
    .join("\n");
}

export function generateInternalFile(options: InternalFileOptions): string {
  const lines: string[] = [];

  lines.push(FILE_HEADER);
  lines.push(
    'import type { PgDatabase, PgQueryResultHKT } from "drizzle-orm/pg-core";',
  );
  lines.push(`import type * as __schema from "${options.schemaImport}";`);
  lines.push("");

  // DrizzleDb type alias
  lines.push(
    "export type DrizzleDb = PgDatabase<PgQueryResultHKT, typeof __schema>;",
  );
  lines.push("");

  return lines.join("\n");
}

export interface TableFileOptions {
  schemaImport: string;
  internalImport: string;
  runtimeImport: string;
}

export function generateTableFile(
  table: AnalyzedTable,
  options: TableFileOptions,
): string {
  const hasComposite = hasCompositeIndexes(table);

  const compositeImports = hasComposite
    ? `
  buildCompositeLookupMap,
  serializeCompositeKey,
  queryCompositeKey,`
    : "";

  const imports = `import DataLoader from "dataloader";
import { inArray } from "drizzle-orm";
import type { InferSelectModel } from "drizzle-orm";
import {
  DrizzleLoaderNotFound,
  buildLookupMap,
  lookupOrError,${compositeImports}
} from "${options.runtimeImport}";
import * as __schema from "${options.schemaImport}";
import { type DrizzleDb } from "${options.internalImport}";`;

  const loaderFn = generateTableLoaderFunctionExported(table);

  return `${FILE_HEADER}${imports}

${loaderFn}
`;
}

function hasCompositeIndexes(table: AnalyzedTable): boolean {
  if (table.primaryKey && table.primaryKey.columns.length > 1) return true;
  return table.indexes.some((idx) => idx.columns.length > 1);
}

function generateTableLoaderFunctionExported(table: AnalyzedTable): string {
  const tablePascal = toPascalCase(table.name);
  const lines: string[] = [];

  lines.push(`export function create${tablePascal}Loaders(db: DrizzleDb) {`);

  const loaders: string[] = [];

  // Single-column primary key
  if (table.primaryKey && table.primaryKey.columns.length === 1) {
    const col = table.primaryKey.columns[0];
    if (col) {
      loaders.push(
        generateUniqueLoader(table, col.name, col.tsType, { useHelpers: true }),
      );
    }
  }
  // Composite primary key
  else if (table.primaryKey && table.primaryKey.columns.length > 1) {
    loaders.push(
      generateCompositeUniqueLoader(table, table.primaryKey.columns),
    );
  }

  for (const idx of table.indexes) {
    // Single-column index
    if (idx.columns.length === 1) {
      const col = idx.columns[0];
      if (!col) continue;
      if (idx.unique) {
        loaders.push(
          generateUniqueLoader(table, col.name, col.tsType, {
            useHelpers: true,
          }),
        );
      } else {
        loaders.push(generateNonUniqueLoader(table, col.name, col.tsType));
      }
    }
    // Composite index
    else if (idx.columns.length > 1) {
      if (idx.unique) {
        loaders.push(generateCompositeUniqueLoader(table, idx.columns));
      } else {
        loaders.push(generateCompositeNonUniqueLoader(table, idx.columns));
      }
    }
  }

  for (const loader of loaders) {
    lines.push(indentLines(loader, 2));
  }

  const loaderNames = getLoaderNames(table);
  lines.push(`  return { ${loaderNames.join(", ")} };`);
  lines.push("}");

  return lines.join("\n");
}

export interface EntryPointFileOptions {
  schemaImport: string;
  internalImport: string;
  tableImportPrefix: string;
  importExtension: string;
  runtimeImport: string;
}

export function generateEntryPointFile(
  tables: AnalyzedTable[],
  options: EntryPointFileOptions,
): string {
  const ext = options.importExtension;

  // Generate imports for each table's loader function
  const tableImports = tables
    .map((t) => {
      const fnName = `create${toPascalCase(t.name)}Loaders`;
      const fileName = toCamelCase(t.name);
      return `import { ${fnName} } from "${options.tableImportPrefix}${fileName}${ext}";`;
    })
    .join("\n");

  // Import DrizzleDb type from _internal
  const typeImport = `import { type DrizzleDb } from "${options.internalImport}";`;

  // Re-export DrizzleLoaderNotFound from runtime
  const reExport = `export { DrizzleLoaderNotFound } from "${options.runtimeImport}";`;

  // Generate factory function that combines all table loaders
  const factoryFn = generateEntryPointFactory(tables);

  return `${FILE_HEADER}${tableImports}
${typeImport}

${reExport}

${factoryFn}
`;
}

function generateEntryPointFactory(tables: AnalyzedTable[]): string {
  const lines: string[] = [];

  lines.push("export function createDrizzleLoaders(db: DrizzleDb) {");
  lines.push("  return {");

  for (const table of tables) {
    const tablePascal = toPascalCase(table.name);
    lines.push(`    ${table.name}: create${tablePascal}Loaders(db),`);
  }

  lines.push("  };");
  lines.push("}");

  return lines.join("\n");
}

export interface MultiFileOutputOptions {
  schemaImport: string;
  importExtension: string;
  dialect?: "pg";
}

export function generateMultiFileOutput(
  tables: AnalyzedTable[],
  options: MultiFileOutputOptions,
): Map<string, string> {
  const ext = options.importExtension;
  const dialect = options.dialect ?? "pg";
  const files = new Map<string, string>();

  // Analyze runtime usage to generate minimal runtime file
  const runtimeUsage = analyzeRuntimeUsage(tables);

  // _runtime.ts - runtime helpers
  files.set("drizzleloaders/_runtime.ts", generateRuntimeFile(runtimeUsage));

  // _internal.ts - schema import needs adjustment for being inside drizzleloaders/
  // If schemaImport is "./schema.js", from drizzleloaders/_internal.ts it becomes "../schema.js"
  const internalSchemaImport = adjustSchemaImportPath(options.schemaImport);
  files.set(
    "drizzleloaders/_internal.ts",
    generateInternalFile({ schemaImport: internalSchemaImport, dialect }),
  );

  // Per-table files
  for (const table of tables) {
    const fileName = `drizzleloaders/${toCamelCase(table.name)}.ts`;
    // Schema import from drizzleloaders/users.ts to schema also needs "../" prefix
    const tableSchemaImport = adjustSchemaImportPath(options.schemaImport);
    files.set(
      fileName,
      generateTableFile(table, {
        schemaImport: tableSchemaImport,
        internalImport: `./_internal${ext}`,
        runtimeImport: `./_runtime${ext}`,
      }),
    );
  }

  // Entry point
  files.set(
    "drizzleloaders.ts",
    generateEntryPointFile(tables, {
      schemaImport: options.schemaImport,
      internalImport: `./drizzleloaders/_internal${ext}`,
      tableImportPrefix: "./drizzleloaders/",
      importExtension: ext,
      runtimeImport: `./drizzleloaders/_runtime${ext}`,
    }),
  );

  return files;
}

/**
 * Adds "../" prefix for imports from inside drizzleloaders/ directory.
 * - "./schema.js" becomes "../schema.js"
 * - "../db/schema.js" becomes "../../db/schema.js"
 * - Package imports like "@myapp/db" are returned unchanged
 */
function adjustSchemaImportPath(schemaImport: string): string {
  if (schemaImport.startsWith("./")) {
    return `../${schemaImport.slice(2)}`;
  }
  if (schemaImport.startsWith("../")) {
    return `../${schemaImport}`;
  }
  return schemaImport;
}
